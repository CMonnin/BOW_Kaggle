{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##  Bag of Words, Bag of Popcorn\n","\n","[Bag of Words, Bag of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. \n","\n","Use NLP feature pre-processing (using, SKLearn, Gensim, Spacy or Hugginface) to build the best classifier you can. Use a  feature pipeline, and gridsearch for your final model.\n","\n","A succesful project should get 90% or more on a **holdout** dataset you kept for yourself."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["################################################\n","# General imports\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import re\n","\n","\n","################################################\n","# gensim imports\n","import gensim\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","################################################\n","# Sklearn imports\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.experimental import enable_halving_search_cv \n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import HalvingGridSearchCV\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import MaxAbsScaler\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import QuantileTransformer \n","from sklearn.preprocessing import Normalizer\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Resources:\n","\n","\n","- doc2vec white paper: https://cs.stanford.edu/~quocle/paragraph_vector.pdf\n","- https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n","- https://github.com/RaRe-Technologies/gensim/blob/bcee414663bdcbdf6a58684531ee69c6949550bf/docs/src/gallery/howtos/run_doc2vec_imdb.py"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"elapsed":2746,"status":"error","timestamp":1616634058840,"user":{"displayName":"jasleen Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitSy-VVABi645nqScpV23oW5NBCAa7lTQqdIKl=s64","userId":"12125715966921775581"},"user_tz":240},"id":"FExxxb5f5Yye","outputId":"a367de4b-8fec-4d22-efcf-e015fefc561a","trusted":true},"outputs":[],"source":["# exercise 2\n","# Import the pandas package, then use the \"read_csv\" function to read\n","# the labeled training data\n","train_data = pd.read_csv('../data/labeledTrainData.tsv',delimiter='\\t')\n","test_data = pd.read_csv('../data/testData.tsv',delimiter='\\t')\n","unlabeled_train_data = pd.read_csv('../data/unlabeledTrainData.tsv',delimiter='\\t', on_bad_lines='skip')\n","sample_submission = pd.read_csv('../data/sampleSubmission.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def text_clean(text):\n","\n","    text= BeautifulSoup(text, \"html.parser\")\n","    text = text.get_text(separator=\" \")\n","    \n","    \n","    # # Remove mentions\n","    # mention_pattern = r'@\\w+'\n","    # text = re.sub(mention_pattern, '', text)  \n","\n","    #text in lower case\n","    text = str(text).lower()\n","\n","    # #remove emojis\n","    # text = emoji.demojize(text)\n","    # text = re.sub(r':\\w+', '', text)\n","\n","    #remove words starting with '@'\n","    text = re.sub(r'@\\w+', '', text)\n","\n","    #remove points\n","    text = text.replace('.', '') \n","\n","    #remove 2 points\n","    text = text.replace(':', '')\n","\n","    #remove urls\n","    text = re.sub('http\\S+|www.\\S+', '', text)\n","    \n","    #convert currency signs to words\n","    currency_dict = {\n","    '$': 'dollars',\n","    '£': 'pounds',\n","    '€': 'euros',\n","    '¥': 'yen',\n","    '₹': 'rupees',\n","    }\n","    for symbol, word in currency_dict.items():\n","        text = text.replace(symbol, word)\n","\n","    # #convert numbers into words\n","    # matches = re.findall(r'\\d+', text)\n","    # for match in matches:\n","    #     word = num2words(int(match))\n","    #     text = text.replace(match, word)\n","\n","    #remove numeric values\n","    text = re.sub(r'\\d+', '', text)\n","\n","    #use the contractions to expand contractions (ex. doesn't to does not)\n","    # text = contractions.fix(text)\n","\n","    # #remove punctuation\n","    # translator = str.maketrans('', '', string.punctuation)\n","    # text = text.translate(translator)\n","   \n","\n","    #remove multiple spaces\n","    text = re.sub(' +', ' ', text)\n","\n","    #remove <> and content inside\n","    text = re.sub('<.*?>+', '', text)\n","\n","    #remove any ASCII character thats left like ¿\n","    text = text.replace(\"¿\", '')\n","    text = re.sub(r'[\\\\\\'\"‘’“”()]', '', text)\n","\n","\n","    text= BeautifulSoup(text, \"html.parser\")\n","    text = text.get_text(separator=\" \")\n","    return text"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# not used\n","\n","def remove_html(text):\n","    text= BeautifulSoup(text, \"html.parser\")\n","    text = text.get_text(separator=\" \")\n","    return text"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  warnings.warn(\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  warnings.warn(\n"]}],"source":["#trying more text cleaning\n","\n","\n","train_data['review'] = train_data['review'].apply(text_clean)\n","train_data['tokens'] = train_data['review'].apply(gensim.utils.simple_preprocess)\n","\n","\n","unlabeled_train_data['review'] = unlabeled_train_data['review'].apply(text_clean)\n","unlabeled_train_data['tokens'] = unlabeled_train_data['review'].apply(gensim.utils.simple_preprocess)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["1    12500\n","0    12500\n","Name: sentiment, dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_data.sentiment.value_counts()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["X = train_data['tokens']\n","y = train_data['sentiment']\n","# stratify as we want 0 and 1s in the train and test altho probably not necessary as there's an equal number of each\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n","X_train, X_test, y_train, y_test = list(X_train), list(X_test), list(y_train), list(y_test)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Larger unlabeled training set used to train the gensim model doc2vec\n","X_un = unlabeled_train_data['tokens']"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import multiprocessing\n","cores = multiprocessing.cpu_count()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["doc_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n","doc_test = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]\n","doc_unlabeled = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_un)]\n","#DBOW is the doc2vec model analogous to Skip-gram model in word2vec\n","# dm = distrubuted bag of words\n","# vector_size = num of features\n","# epoch = number of times the model is run \n","# min_count = set to 2 so it doesn't look at words that don't occur oftern\n","# eg a word needs to be seen twice to be included\n","model_dbow = Doc2Vec(vector_size=100, \n","                     dm = 0, \n","                     window=8, \n","                     workers=cores,\n","                     epochs=40,\n","                     min_count=4)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["full_doc = doc_test+doc_train+doc_unlabeled"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# buld the vocabulary for the model\n","model_dbow.build_vocab(full_doc)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model_dbow.train(doc_unlabeled, \n","                 total_examples=model_dbow.corpus_count,\n","                 epochs=model_dbow.epochs\n","                )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Vectorizing the training and test sets"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["train_vec_list = []\n","for doc_id in range(len(doc_train)):\n","    inferred_vector = model_dbow.infer_vector(doc_train[doc_id].words)\n","    train_vec_list.append(inferred_vector)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["test_vec_list= []\n","for doc_id in range(len(doc_test)):\n","    inferred_vector = model_dbow.infer_vector(doc_test[doc_id].words)\n","    test_vec_list.append(inferred_vector)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# not used\n","\n","def doc_to_vector_list(doc,convert=True):\n","    \n","    '''# method to covert a doc using the doc2vec model\n","        if convert=True it will convert the doc (like pandas in_place)\n","        if convert=False it will return a copy'''\n","    temp_vector_list=[]\n","    if convert == True:\n","        for doc_id in range(len(doc)):\n","            inferred_vector = model_dbow.infer_vector(doc[doc_id].words)\n","            temp_vector_list.append(inferred_vector)\n","        doc = temp_vector_list\n","        return doc\n","    else:\n","        for doc_id in range(len(doc)):\n","            inferred_vector = model_dbow.infer_vector(doc[doc_id].words)\n","            temp_vector_list.append(inferred_vector)\n","        return temp_vector_list"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# redefining X_train and X_test and the vectorized versions of themselves\n","\n","X_train = train_vec_list\n","X_test = test_vec_list"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Initial classification models"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"]}],"source":["logit_model = LogisticRegression(max_iter=5000)\n","train_fit_logit = logit_model.fit(X_train,y_train)           \n","y_pred_logit = logit_model.predict(X_test)\n","\n","rand_forest_model = RandomForestClassifier(n_estimators=100,\n","                                           random_state=42,criterion='gini', \n","                                           n_jobs = -1,\n","                                           oob_score=True)\n","rand_forest_model.fit(X_train,y_train)\n","y_pred_forest = rand_forest_model.predict(X_test)\n","\n","Knn_model = KNeighborsClassifier()\n","Knn_model.fit(X_train,y_train)\n","y_pred_Knn = Knn_model.predict(X_test)\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88      3125\n","           1       0.88      0.88      0.88      3125\n","\n","    accuracy                           0.88      6250\n","   macro avg       0.88      0.88      0.88      6250\n","weighted avg       0.88      0.88      0.88      6250\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.84      0.84      3125\n","           1       0.84      0.83      0.84      3125\n","\n","    accuracy                           0.84      6250\n","   macro avg       0.84      0.84      0.84      6250\n","weighted avg       0.84      0.84      0.84      6250\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.79      0.79      3125\n","           1       0.79      0.79      0.79      3125\n","\n","    accuracy                           0.79      6250\n","   macro avg       0.79      0.79      0.79      6250\n","weighted avg       0.79      0.79      0.79      6250\n","\n"]}],"source":["print(classification_report(y_test,y_pred_logit))\n","print(classification_report(y_test,y_pred_forest))\n","print(classification_report(y_test,y_pred_Knn))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","logit model has best acc. will try doing a gridsearch to improve it\n","\n","will try PCA in the pipeline too"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["# ########\n","# #######\n","# #TAKES A LONG TIME TO RUN\n","# ########\n","# #######\n","# # Define a pipeline to search for the best combination of PCA truncation\n","# # and classifier regularization.\n","# pca = PCA()\n","# # Define a Standard Scaler to normalize inputs\n","# scaler = RobustScaler()\n","\n","# # set the tolerance to a large value to make the example faster\n","# logistic = LogisticRegression(max_iter=1000, tol=0.1,warm_start=True)\n","# pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"logistic\", logistic)])\n","\n","\n","# # Parameters of pipelines can be set using '__' separated parameter names:\n","# param_grid = {\n","#     \"pca__n_components\": [5, 15, 45, 60, 200],\n","#     \"logistic__C\": np.logspace(-8,8,8),\n","#     'logistic__penalty':['none', 'l1', 'l2', 'elasticnet'],\n","#     'logistic__solver':['newton-cg', 'lbfgs', 'liblinear']\n","# }\n","\n","# search = GridSearchCV(pipe, param_grid, n_jobs=-1,verbose=True)\n","# search.fit(X_train, y_train)\n","# y_pred_logit_GS = search.predict(X_Test)\n","# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n","# print(search.best_params_)\n","# print(classification_report(y_test,y_pred_logit_GS))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----\n","Preparing to test different pre-processing"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Transform training data\n","X1 = StandardScaler().fit_transform(X_train)\n","X2 = MinMaxScaler().fit_transform(X_train)\n","X3 = MaxAbsScaler().fit_transform(X_train)\n","X4 = RobustScaler().fit_transform(X_train)\n","X5 = PowerTransformer().fit_transform(X_train)\n","X6 = QuantileTransformer().fit_transform(X_train)\n","X7 = Normalizer().fit_transform(X_train)\n","# Transforming test data\n","X1_test = StandardScaler().fit_transform(X_test)\n","X2_test = MinMaxScaler().fit_transform(X_test)\n","X3_test = MaxAbsScaler().fit_transform(X_test)\n","X4_test = RobustScaler().fit_transform(X_test)\n","X5_test = PowerTransformer().fit_transform(X_test)\n","X6_test = QuantileTransformer().fit_transform(X_test)\n","X7_test = Normalizer().fit_transform(X_test)\n","\n","\n","X_lst = [X1,X2,X3,X4,X5,X6,X7]\n","X_test_list = [X1_test,X2_test,X3_test,X4_test,X5_test,X6_test,X7_test]\n","X_label = ['Standard','MinMax','MaxAbs','Robust','PowerTransformer','QuantileTransformer','Normalizer']\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----\n","Testing different models"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      0.89      0.88      3125\n","           1       0.88      0.87      0.88      3125\n","\n","    accuracy                           0.88      6250\n","   macro avg       0.88      0.88      0.88      6250\n","weighted avg       0.88      0.88      0.88      6250\n","\n"]}],"source":["from sklearn.linear_model import SGDClassifier\n","sgdc_clf = SGDClassifier()\n","sgdc_clf = sgdc_clf.fit(X1, y_train)\n","y_pred_sgdc = sgdc_clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_sgdc))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.89      0.88      3125\n","           1       0.89      0.88      0.88      3125\n","\n","    accuracy                           0.88      6250\n","   macro avg       0.88      0.88      0.88      6250\n","weighted avg       0.88      0.88      0.88      6250\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]}],"source":["\n","Lsvm_clf = svm.LinearSVC()\n","Lsvm_clf = Lsvm_clf.fit(X1, y_train)\n","y_pred_Lsvm = Lsvm_clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_Lsvm))"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.67      0.66      3125\n","           1       0.66      0.65      0.66      3125\n","\n","    accuracy                           0.66      6250\n","   macro avg       0.66      0.66      0.66      6250\n","weighted avg       0.66      0.66      0.66      6250\n","\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","dtc_clf = DecisionTreeClassifier()\n","dtc_clf = dtc_clf.fit(X1, y_train)\n","y_pred_dtc = dtc_clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_dtc))"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.81      0.81      3125\n","           1       0.81      0.82      0.81      3125\n","\n","    accuracy                           0.81      6250\n","   macro avg       0.81      0.81      0.81      6250\n","weighted avg       0.81      0.81      0.81      6250\n","\n"]}],"source":["from sklearn.naive_bayes import BernoulliNB\n","bnb_clf = BernoulliNB()\n","bnb_clf = bnb_clf.fit(X1, y_train)\n","y_pred_bnb = bnb_clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_bnb))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.86      0.86      3125\n","           1       0.86      0.86      0.86      3125\n","\n","    accuracy                           0.86      6250\n","   macro avg       0.86      0.86      0.86      6250\n","weighted avg       0.86      0.86      0.86      6250\n","\n"]}],"source":["import xgboost as xgb\n","xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n","xgb_clf = xgb_clf.fit(X1, y_train)\n","y_pred_xgb = xgb_clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_xgb))\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88784\n"]}],"source":["clf = svm.SVC()\n","clf = clf.fit(X1, y_train)\n","y_pred_svm = clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_svm))\n","print(accuracy_score(y_test,y_pred_svm))\n","#best one yet"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.89      0.88      3125\n","           1       0.89      0.88      0.88      3125\n","\n","    accuracy                           0.88      6250\n","   macro avg       0.88      0.88      0.88      6250\n","weighted avg       0.88      0.88      0.88      6250\n","\n"]}],"source":["# Best logit model \n","\n","logit_model_best=LogisticRegression(C=0.001, penalty= 'l2', solver='newton-cg',max_iter=10000)\n","logit_model_best = logit_model_best.fit(X1,y_train)\n","y_pred_best_logit = logit_model_best.predict(X1_test)\n","print(classification_report(y_test,y_pred_best_logit ))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----\n","I went back and forth between the next few cells updating according the best results \n","SVC was the best classifier I fond\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["***********\n","Standard\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88784\n","************\n","***********\n","MinMax\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.70      0.81      3125\n","           1       0.76      0.96      0.85      3125\n","\n","    accuracy                           0.83      6250\n","   macro avg       0.86      0.83      0.83      6250\n","weighted avg       0.86      0.83      0.83      6250\n","\n","0.83408\n","************\n","***********\n","MaxAbs\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.87      0.88      3125\n","           1       0.88      0.90      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88576\n","************\n","***********\n","Robust\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88768\n","************\n","***********\n","PowerTransformer\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.88      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88768\n","************\n","***********\n","QuantileTransformer\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88      3125\n","           1       0.88      0.89      0.88      3125\n","\n","    accuracy                           0.88      6250\n","   macro avg       0.88      0.88      0.88      6250\n","weighted avg       0.88      0.88      0.88      6250\n","\n","0.88176\n","************\n","***********\n","Normalizer\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.88      0.89      3125\n","           1       0.88      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88816\n","************\n"]}],"source":["# finding best scaling method to apply\n","# standard scaler looks good\n","for i,j in enumerate(X_lst):\n","    clf = svm.SVC()\n","    clf = clf.fit(j, y_train)\n","    y_pred_svm = clf.predict(X_test_list[i])\n","    print('***********')\n","    print(X_label[i])\n","    print(classification_report(y_test,y_pred_svm))\n","    print(accuracy_score(y_test,y_pred_svm))\n","    print('************')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["n_iterations: 5\n","n_required_iterations: 5\n","n_possible_iterations: 5\n","min_resources_: 231\n","max_resources_: 18750\n","aggressive_elimination: False\n","factor: 3\n","----------\n","iter: 0\n","n_candidates: 84\n","n_resources: 231\n","Fitting 5 folds for each of 84 candidates, totalling 420 fits\n","----------\n","iter: 1\n","n_candidates: 28\n","n_resources: 693\n","Fitting 5 folds for each of 28 candidates, totalling 140 fits\n","----------\n","iter: 2\n","n_candidates: 10\n","n_resources: 2079\n","Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","----------\n","iter: 3\n","n_candidates: 4\n","n_resources: 6237\n","Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","----------\n","iter: 4\n","n_candidates: 2\n","n_resources: 18711\n","Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"]},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Best parameter (CV score=0.887):\n","{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.888\n"]}],"source":["# doing a full GridSearchCV takes a long time. While trying a bunch of hyperparameter values this method\n","# was quicker \n","# Default values seem to be the best =/\n","clf = svm.SVC(max_iter=5000)\n","\n","svc_param_grid = {\n","                'C': [0.1, 1, 10, 100],  \n","                'gamma': ['scale','auto',1, 0.1, 0.01, 0.001, 0.0001], \n","                'kernel': ['linear','rbf','sigmoid']\n","                 }  \n","search = HalvingGridSearchCV(clf, svc_param_grid, verbose =True,n_jobs=-1,scoring='accuracy')\n","search.fit(X1, y_train)\n","print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n","print(search.best_params_)\n","y_pred_HGS = search.predict(X1_test)\n","print(classification_report(y_test,y_pred_HGS))\n","print(accuracy_score(y_test,y_pred_HGS))"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# Using the finalised hyperparameters I did a full GridSearch\n","# Tried these parameters but default were better\n","# clf = svm.SVC(max_iter=5000)\n","\n","# svc_param_grid = {\n","#                 'C': [0.1, 1, 10, 100],  \n","#                 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n","#                 'kernel': ['linear','rbf','sigmoid']\n","#                  }  \n","   \n","# search = GridSearchCV(clf, svc_param_grid, refit = True, verbose =True,n_jobs=-1,scoring='accuracy')\n","# search.fit(X1, y_train)\n","# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n","# print(search.best_params_)\n","# y_pred_GS = search.predict(X1_test)\n","# print(classification_report(y_test,y_pred_GS))\n","# print(accuracy_score(y_test,y_pred_GS))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Fitting 5 folds for each of 32 candidates, totalling 160 fits\n","\n","Best parameter (CV score=0.876):\n","\n","{'C': 333.334, 'gamma': 0.001, 'kernel': 'rbf'}"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.89      0.89      3125\n","           1       0.89      0.89      0.89      3125\n","\n","    accuracy                           0.89      6250\n","   macro avg       0.89      0.89      0.89      6250\n","weighted avg       0.89      0.89      0.89      6250\n","\n","0.88784\n"]}],"source":["# Default values gave best results  after all that hyperparameter tuning\n","# I guess they're defaults for a reason . . . \n","clf = svm.SVC()\n","clf = clf.fit(X1, y_train)\n","y_pred_svm = clf.predict(X1_test)\n","print(classification_report(y_test,y_pred_svm))\n","print(accuracy_score(y_test,y_pred_svm))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Preparing holdout data\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  warnings.warn(\n"]}],"source":["test_data['review'] = test_data['review'].apply(text_clean)\n","test_data['tokens'] = test_data['review'].apply(gensim.utils.simple_preprocess)\n","\n","X_holdout = test_data['tokens']\n","doc_holdout = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_holdout)]"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["holdout_vec_list = []\n","for doc_id in range(len(doc_holdout)):\n","    inferred_vector = model_dbow.infer_vector(doc_holdout[doc_id].words)\n","    holdout_vec_list.append(inferred_vector)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["X_holdout = holdout_vec_list\n","X_holdout = StandardScaler().fit_transform(X_holdout)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 0, 0, ..., 0, 1, 1])"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["\n","clf = svm.SVC()\n","clf = clf.fit(X1, y_train)\n","y_pred_holdout = clf.predict(X_holdout)\n","y_pred_holdout"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["sample_submission = pd.read_csv('../data/sampleSubmission.csv')"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12311_10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8348_2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5828_4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7186_2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12128_7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>2155_10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>59_10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>2531_1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24998</th>\n","      <td>7772_8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24999</th>\n","      <td>11465_10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25000 rows × 2 columns</p>\n","</div>"],"text/plain":["             id  sentiment\n","0      12311_10          0\n","1        8348_2          0\n","2        5828_4          0\n","3        7186_2          0\n","4       12128_7          0\n","...         ...        ...\n","24995   2155_10          0\n","24996     59_10          0\n","24997    2531_1          0\n","24998    7772_8          0\n","24999  11465_10          0\n","\n","[25000 rows x 2 columns]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["sample_submission"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["sample_submission['sentiment']= y_pred_holdout"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["sample_submission.to_csv('sample_sub_CM.csv',index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----\n","This submission gets an 89 on kaggle\n","\n","My disappointment is immeasurable and my day is ruined"]}],"metadata":{"colab":{"name":"workshop pt2 ANSWER.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
